{
  "keywords": ["Flink", "日志文件批处理", "聚合统计", "接口错误码", "JSON解析", "Scala", "大数据处理", "数据聚合", "性能调优", "mvn", "flink sql", "4G日志", "错误码统计", "日志处理", "大文件处理"],
  "description": "本文介绍如何使用 Apache Flink 进行大规模日志文件批处理，以统计每小时接口错误码。文章涵盖了 Flink 环境配置、Scala 代码实现、JSON 数据解析、数据聚合以及 Jar 包打包和提交等步骤，并提供了完整的代码示例和详细的步骤说明。适用于处理 4G 压缩包解压后 40-50G 的大规模 JSON 日志数据，并针对接口错误码进行统计分析。",
  "title": "使用 Flink 进行大规模 JSON 日志文件批处理：高效统计接口错误码"
}
